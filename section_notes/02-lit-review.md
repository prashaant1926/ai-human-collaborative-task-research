# Literature Review Notes

## Key Themes Across Literature

### Theme 1: Human-AI Teaming Frameworks

The literature converges on viewing human-AI collaboration through a **teaming lens** rather than a tool-use lens. Key points:

- Humans and AI should be viewed as teammates with complementary capabilities
- Effective teams require shared mental models and mutual understanding
- Trust calibration is critical for appropriate reliance

**Key Papers:**
- Bansal et al. (2019) - "Beyond Accuracy: The Role of Mental Models in Human-AI Team Performance"
- Amershi et al. (2019) - "Guidelines for Human-AI Interaction"
- Horvitz (1999) - "Principles of Mixed-Initiative User Interfaces"

### Theme 2: Role Allocation in Collaborative Systems

Prior work has explored role allocation primarily in:
- **Crowdsourcing**: Dynamic task routing based on worker expertise
- **CSCW**: Role-based access and responsibility in groupware
- **Robotics**: Human-robot role negotiation

**Gap Identified:** Limited work on dynamic role allocation specifically for AI-assisted research tasks where both parties can contribute intellectually.

### Theme 3: Feedback Loops and Iterative Refinement

Literature on iterative human-AI workflows shows:
- Multiple rounds of feedback improve output quality
- Diminishing returns after 3-4 iterations typically
- Feedback specificity matters more than frequency

**Key Papers:**
- Kreutzer et al. (2018) - "Reliability and Learnability of Human Bandit Feedback"
- Ziegler et al. (2019) - "Fine-Tuning Language Models from Human Preferences"

### Theme 4: Cognitive Load in Human-AI Interaction

Research indicates:
- AI assistance can reduce cognitive load for routine tasks
- AI assistance can increase cognitive load for verification tasks
- Optimal load distribution depends on task type and user expertise

## Literature Gaps

1. **Long-term collaboration dynamics**: Most studies focus on single-session interactions
2. **Research-specific tasks**: Limited work on complex, open-ended intellectual tasks
3. **Adaptive role boundaries**: No systematic study of when/how roles should shift
4. **Knowledge accumulation**: How shared understanding develops over time

## Theoretical Foundations

### Distributed Cognition (Hutchins, 1995)
- Cognitive processes distributed across people, artifacts, and environment
- Relevant for understanding how AI extends human cognition

### Activity Theory (Engestr√∂m, 1987)
- Tools mediate human activity
- AI as a mediating artifact in research activity

### Transactive Memory Systems (Wegner, 1987)
- Groups develop shared knowledge of "who knows what"
- Applicable to human-AI pairs developing mutual awareness

## Papers to Review

| Paper | Relevance | Status |
|-------|-----------|--------|
| "Human-AI Collaboration in Data Science" (Wang et al., 2019) | High | To read |
| "Collaborative Intelligence" (Wilson & Daugherty, 2018) | High | To read |
| "The Future of Human-AI Collaboration" (Dellermann et al., 2019) | High | To read |
| "Guidelines for Human-AI Interaction" (Amershi et al., 2019) | High | Read |
| "Human Factors in AI" (Shneiderman, 2020) | Medium | To read |

## Synthesis Notes

The literature suggests a shift from viewing AI as a **tool** to viewing it as a **collaborator**, but lacks:
1. Empirical frameworks for measuring collaboration effectiveness
2. Design principles specific to research tasks
3. Understanding of long-term dynamics

Our work addresses these gaps by proposing and evaluating dynamic role allocation in sustained research collaboration.
